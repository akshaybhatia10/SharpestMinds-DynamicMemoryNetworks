{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BabI Exploration and Simple Baseline\n",
    "\n",
    "This notebook provides a brief overview of the BabI dataset. Also, we implement a simple two layer deep neural network for one of the 20 tasks in Babi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running this notebook, make sure to download the data+glove embeddings(run download_data.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import re\n",
    "from functools import reduce\n",
    "import sys\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Facebook bAbI-10k dataset consists of 20 tasks and has been used as a benchmark in many question answering papers. Each task has a different type of question such as single supporting fact\n",
    "questions, two supporting fact questions, yes no questions, counting questions, etc.\n",
    "Here we are using the English version of the dataset with 10,000 training examples and 1000 test examples.\n",
    "All examples consist of an input-question-answer tuple. The input is a variable length passage of\n",
    "text. The type of question and answer depends on the task. For example, some tasks have yes/no\n",
    "answers while others are focused on positional reasoning or counting. For each question-answer\n",
    "pair, the dataset also gives the line numbers of the input passage that is relevant to the answer. Every\n",
    "answer in the bAbI dataset is one word. Examples from the dataset can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/tasks_1-20_v1-2/en-10k/'\n",
    "GLOVE_PATH = 'data/glove.6B.50d.txt'\n",
    "task_number = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_task_file(directory, task_number, type='train'):\n",
    "    '''Returns task file name\n",
    "    :param String directory\n",
    "    :param int task\n",
    "    :return String current_task_file \n",
    "    '''\n",
    "    all_paths = os.listdir(directory)\n",
    "    all_files = [os.path.join(directory, folder) for folder in all_paths]\n",
    "    t = 'qa{}_'.format(task_number)\n",
    "    current_task_file = [f for f in all_files if t in f and type in f][0]\n",
    "    return current_task_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_train.txt\n"
     ]
    }
   ],
   "source": [
    "current_task_file = get_current_task_file(DATASET_PATH, task_number)\n",
    "print (current_task_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a yes no question answering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Mary moved to the bathroom.',\n",
       " '2 Sandra journeyed to the bedroom.',\n",
       " '3 Is Sandra in the hallway? \\tno\\t2',\n",
       " '4 Mary went back to the bedroom.',\n",
       " '5 Daniel went back to the hallway.',\n",
       " '6 Is Daniel in the bathroom? \\tno\\t5',\n",
       " '7 Sandra went to the kitchen.',\n",
       " '8 Daniel went back to the bathroom.',\n",
       " '9 Is Daniel in the office? \\tno\\t8',\n",
       " '10 Daniel picked up the football there.',\n",
       " '11 Daniel went to the bedroom.',\n",
       " '12 Is Daniel in the bedroom? \\tyes\\t11',\n",
       " '13 John travelled to the office.',\n",
       " '14 Sandra went to the garden.',\n",
       " '15 Is Daniel in the bedroom? \\tyes\\t11']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [line.strip() for line in open(current_task_file).read().split('\\n')[:-1]]\n",
    "examples[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the full dataset as a single python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(inputs):\n",
    "    return reduce(lambda x,y:x+y, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(current_task_file):\n",
    "    '''Returns a list of tuples consisting of\n",
    "       input, question and answer pairs\n",
    "    param: String current_task_file\n",
    "    '''\n",
    "\n",
    "    data = open(current_task_file).read()\n",
    "    data = data.split('\\n')[:-1]\n",
    "    data = [line.strip() for line in data]\n",
    "    \n",
    "    new = False\n",
    "    dataset = list()\n",
    "    inputs = list()\n",
    "    \n",
    "    for line in data:\n",
    "        idx, line = line.strip().split(' ', 1)\n",
    "        if int(idx) == 1:\n",
    "            new = True\n",
    "            inputs = []\n",
    "        if '\\t' in line:\n",
    "            question, answer, _ = line.split('\\t')\n",
    "            new_inputs = [i for i in inputs if i]\n",
    "            question = [s.strip() for s in re.split('(\\W+)?', question) if s.strip()]\n",
    "            dataset.append((new_inputs, question, answer))\n",
    "            inputs.append('')\n",
    "        else:\n",
    "            inputs.append([s.strip() for s in re.split('(\\W+)?', line) if s.strip()])\n",
    "            \n",
    "    return [(concat(i), q, a) for i, q, a in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, split_ratio, shuffle=True):\n",
    "    '''Returns the training and validation set\n",
    "    :param data\n",
    "    :param split_ration\n",
    "    :param shuffle\n",
    "    :Returns train_data, test_data\n",
    "    '''\n",
    "    if shuffle == True:\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "    idx = int(len(data) * split_ratio)\t\n",
    "    train_data, test_data = data[:idx], data[idx:]\t\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Glove embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embedding_file(path_to_file):\n",
    "    '''Loads the glove embedding file\n",
    "    :param path_to_file\n",
    "    :Returns file\n",
    "    '''\n",
    "    file = csv.reader(open(path_to_file), delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "    file = {line[0]: np.array(list(map(float, line[1:]))) for line in file}\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the inputs and questions to vectors using pre-trained glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_vector(dataset, embedding_file):\n",
    "    '''Returns the training and validation set\n",
    "    :param dataset\n",
    "    :param embedding_file\n",
    "    :Returns inputs, questions, answers\n",
    "    '''\n",
    "    inputs, questions, answers = list(), list(), list()\n",
    "    for i, q, a in dataset:\n",
    "        vec_i = list()\n",
    "        for word in i:\n",
    "            word = word.lower()\n",
    "            if word in embedding_file:\n",
    "                vi = embedding_file[word]\n",
    "            else:\n",
    "                vi = np.random.choice(np.random.uniform(0, 1, 50))\n",
    "                vi /= np.sum(np.random.uniform(0, 1, 50))\n",
    "\n",
    "            vec_i.append(vi)\n",
    "        inputs.append(vec_i)\n",
    "\n",
    "        vec_q = list()\n",
    "        for word in q:\n",
    "            word = word.lower()\n",
    "            if word in embedding_file:\n",
    "                vq = embedding_file[word]\n",
    "            else:\n",
    "                vq = np.random.choice(np.random.uniform(0, 1, 50))\n",
    "                vq /= np.sum(np.random.uniform(0, 1, 50))\n",
    "\n",
    "            vec_q.append(vq)\n",
    "        questions.append(vec_q)\n",
    "\n",
    "        if a == 'yes':\n",
    "            ans = np.array([1])\n",
    "            answers.append(ans)\n",
    "        else:\n",
    "            ans = np.array([0])\n",
    "            answers.append(ans)\n",
    "\n",
    "    return inputs, questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little exploration on preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.'], ['Is', 'Sandra', 'in', 'the', 'hallway', '?'], 'no')\n",
      "[ 0.69917   0.64303  -1.439     0.24653   0.5186    0.074237  0.14794\n",
      " -0.53328   0.42334   0.52874  -0.16226   0.39229   0.2929   -0.049215\n",
      " -0.22758   0.0278    0.81454   0.085199 -0.084373 -0.017206 -0.50549\n",
      "  0.56167   0.043883 -0.11787   0.72582  -0.97883  -0.92599   0.31475\n",
      "  0.65451   0.43346   2.9418   -0.86313  -0.097198 -1.5291   -0.39909\n",
      "  0.22361  -0.55267  -0.24998  -0.60628  -0.14298  -0.24146  -0.57472\n",
      "  0.19233   0.94781   0.075044 -0.085379  0.086206  0.24632   0.52126\n",
      "  0.11655 ]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(current_task_file)\n",
    "embedding_file = load_embedding_file(GLOVE_PATH)\n",
    "print (dataset[0])\n",
    "print (embedding_file['nature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBED_DIM = 50\n",
    "\n",
    "def concatenate(inputs, questions):\n",
    "    inp_que = []\n",
    "\n",
    "    examples = len(inputs)\n",
    "    for i in range(examples):\n",
    "        inp_vec = np.zeros((1, EMBED_DIM))\n",
    "        for c in inputs[i]:\n",
    "            inp_vec += c\n",
    "\n",
    "        que_vec = np.zeros((1, EMBED_DIM))\n",
    "        for c in questions[i]:\n",
    "            que_vec += c\n",
    "\n",
    "        v = np.concatenate((inp_vec, que_vec), 1)\n",
    "        inp_que.append(v[0])\n",
    "\n",
    "    return inp_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batches(X, Y, batch_size):\n",
    "    counts = len(X)\n",
    "\n",
    "    for n in range(0, counts, batch_size):\n",
    "        x = X[n:min(n+batch_size, counts)]\n",
    "        y = Y[n:min(n+batch_size, counts)]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 100) (2000, 100) (8000, 1) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data/tasks_1-20_v1-2/en-10k'\n",
    "task_number = 6\n",
    "current_task_file = get_current_task_file(PATH, task_number)    \n",
    "dataset = load_dataset(current_task_file)\n",
    "train_data, test_data = train_test_split(dataset, split_ratio=0.8)\n",
    "embedding_file = load_embedding_file('data/glove.6B.50d.txt')\n",
    "\n",
    "train_inputs, train_questions, train_answers = convert_to_vector(train_data, embedding_file)\n",
    "test_inputs, test_questions, test_answers = convert_to_vector(test_data, embedding_file)\n",
    "\n",
    "X_train = np.array(concatenate(train_inputs, train_questions))\n",
    "X_test = np.array(concatenate(test_inputs, test_questions))\n",
    "y_train = np.array(train_answers)\n",
    "y_test = np.array(test_answers)\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for this notebook(baseline) is a simple two layer Neural Network. Model -> All of the word vectors for each word in the input text are summed up. Similarily, sum all of the word vectors for each word in the question text, Then concatenate the both of them together. Using this as input to the 2 layer network, we train the model using gradient descent. We use a batch size of 64, learning rate decay, Adam optimization. The hidden layer size is 200 and we use Relu Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 159.65216064453125, Accuracy: 100.0, Time Taken: 0.36307215690612793\n",
      "Epoch: 100, Loss: 45.659088134765625, Accuracy: 100.0, Time Taken: 0.2920949459075928\n",
      "Epoch: 200, Loss: 3.1209959983825684, Accuracy: 100.0, Time Taken: 0.287182092666626\n",
      "Epoch: 300, Loss: 1.8143832683563232, Accuracy: 100.0, Time Taken: 0.28829407691955566\n",
      "Epoch: 400, Loss: 0.5801846981048584, Accuracy: 100.0, Time Taken: 0.2913849353790283\n",
      "Epoch: 500, Loss: 0.3909987509250641, Accuracy: 100.0, Time Taken: 0.2959451675415039\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time \n",
    "%timeit\n",
    "\n",
    "input_placeholder = tf.placeholder(tf.float32, (None, 100))\n",
    "target_placeholder = tf.placeholder(tf.float32, (None, 1))\n",
    "lr = tf.placeholder(tf.float32)\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal(shape=(100, 200), dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.zeros(200))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=(200, 200), dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.zeros(200))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal(shape=(200, 1), dtype=tf.float32))\n",
    "b3 = tf.Variable(tf.zeros(1))\n",
    "\n",
    "x = tf.nn.relu(tf.add(tf.matmul(input_placeholder, W1), b1))\n",
    "x = tf.nn.relu(tf.add(tf.matmul(x, W2), b2))\n",
    "y = tf.add(tf.matmul(x, W3), b3)\n",
    "y_ = tf.nn.sigmoid(y)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=target_placeholder, logits=y))\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(target_placeholder, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "with sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs+1):\n",
    "        start = time.time()\n",
    "        for x, y in batches(X_train, y_train, 64):\n",
    "            max_learning_rate = 0.003\n",
    "            min_learning_rate = 0.0001\n",
    "            decay_speed = 2000.0\n",
    "            learn = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-epoch/decay_speed)\n",
    "            \n",
    "            _, l, acc  = sess.run([opt, loss, accuracy], feed_dict={input_placeholder:x, target_placeholder:y, lr:learn, pkeep:0.8})\n",
    "        \n",
    "        end = time.time()    \n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print ('Epoch: {}, Loss: {}, Accuracy: {}, Time Taken: {}'.format(epoch, l, acc, (end-start)))                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s - loss: 1.1028 - acc: 0.5014 - val_loss: 0.7940 - val_acc: 0.5030\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.7552 - acc: 0.5122 - val_loss: 1.0386 - val_acc: 0.4975\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.7381 - acc: 0.5115 - val_loss: 0.7037 - val_acc: 0.5100\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.7268 - acc: 0.5178 - val_loss: 0.7909 - val_acc: 0.5190\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.7096 - acc: 0.5346 - val_loss: 0.6752 - val_acc: 0.5840\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6999 - acc: 0.5624 - val_loss: 0.6697 - val_acc: 0.5815\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6775 - acc: 0.5847 - val_loss: 0.6678 - val_acc: 0.5940\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6648 - acc: 0.5950 - val_loss: 0.6360 - val_acc: 0.6325\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6315 - acc: 0.6340 - val_loss: 0.6801 - val_acc: 0.6055\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6198 - acc: 0.6504 - val_loss: 0.5977 - val_acc: 0.6645\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.6066 - acc: 0.6594 - val_loss: 0.6240 - val_acc: 0.6495\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5868 - acc: 0.6714 - val_loss: 0.5839 - val_acc: 0.6905\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5719 - acc: 0.6856 - val_loss: 0.5629 - val_acc: 0.6880\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5565 - acc: 0.6979 - val_loss: 0.5620 - val_acc: 0.6915\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5565 - acc: 0.6986 - val_loss: 0.5467 - val_acc: 0.7015\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5382 - acc: 0.7150 - val_loss: 0.5355 - val_acc: 0.7240\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5239 - acc: 0.7264 - val_loss: 0.5196 - val_acc: 0.7340\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5255 - acc: 0.7241 - val_loss: 0.5045 - val_acc: 0.7285\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5115 - acc: 0.7294 - val_loss: 0.5203 - val_acc: 0.7190\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.5059 - acc: 0.7311 - val_loss: 0.4890 - val_acc: 0.7600\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4972 - acc: 0.7385 - val_loss: 0.5077 - val_acc: 0.7215\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4939 - acc: 0.7381 - val_loss: 0.4777 - val_acc: 0.7495\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4816 - acc: 0.7455 - val_loss: 0.4876 - val_acc: 0.7380\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4827 - acc: 0.7496 - val_loss: 0.4993 - val_acc: 0.7365\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4807 - acc: 0.7531 - val_loss: 0.4715 - val_acc: 0.7560\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4656 - acc: 0.7570 - val_loss: 0.4709 - val_acc: 0.7635\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4748 - acc: 0.7510 - val_loss: 0.4735 - val_acc: 0.7475\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4568 - acc: 0.7600 - val_loss: 0.4764 - val_acc: 0.7405\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4574 - acc: 0.7619 - val_loss: 0.4626 - val_acc: 0.7610\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4547 - acc: 0.7610 - val_loss: 0.4652 - val_acc: 0.7615\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4574 - acc: 0.7555 - val_loss: 0.4734 - val_acc: 0.7645\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4504 - acc: 0.7610 - val_loss: 0.4818 - val_acc: 0.7455\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4476 - acc: 0.7669 - val_loss: 0.4658 - val_acc: 0.7600\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4435 - acc: 0.7669 - val_loss: 0.4578 - val_acc: 0.7610\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4380 - acc: 0.7666 - val_loss: 0.4611 - val_acc: 0.7550\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4401 - acc: 0.7644 - val_loss: 0.4478 - val_acc: 0.7705\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4356 - acc: 0.7715 - val_loss: 0.4708 - val_acc: 0.7405\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4457 - acc: 0.7627 - val_loss: 0.4377 - val_acc: 0.7810\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4452 - acc: 0.7641 - val_loss: 0.4650 - val_acc: 0.7555\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4364 - acc: 0.7709 - val_loss: 0.4528 - val_acc: 0.7545\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4282 - acc: 0.7770 - val_loss: 0.4348 - val_acc: 0.7730\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4350 - acc: 0.7728 - val_loss: 0.4445 - val_acc: 0.7600\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4316 - acc: 0.7702 - val_loss: 0.4588 - val_acc: 0.7655\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4229 - acc: 0.7774 - val_loss: 0.4383 - val_acc: 0.7740\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4153 - acc: 0.7837 - val_loss: 0.4317 - val_acc: 0.7745\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4161 - acc: 0.7839 - val_loss: 0.4492 - val_acc: 0.7550\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4163 - acc: 0.7782 - val_loss: 0.4228 - val_acc: 0.7875\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4255 - acc: 0.7719 - val_loss: 0.4520 - val_acc: 0.7675\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4176 - acc: 0.7772 - val_loss: 0.4331 - val_acc: 0.7775\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4122 - acc: 0.7836 - val_loss: 0.4299 - val_acc: 0.7790\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4097 - acc: 0.7878 - val_loss: 0.4416 - val_acc: 0.7605\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4031 - acc: 0.7923 - val_loss: 0.4487 - val_acc: 0.7640\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4049 - acc: 0.7864 - val_loss: 0.4401 - val_acc: 0.7680\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4028 - acc: 0.7909 - val_loss: 0.4533 - val_acc: 0.7565\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4035 - acc: 0.7855 - val_loss: 0.4319 - val_acc: 0.7745\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3977 - acc: 0.7878 - val_loss: 0.4361 - val_acc: 0.7725\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3949 - acc: 0.7975 - val_loss: 0.4398 - val_acc: 0.7740\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3878 - acc: 0.8039 - val_loss: 0.4252 - val_acc: 0.7755\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3881 - acc: 0.7993 - val_loss: 0.4449 - val_acc: 0.7610\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3882 - acc: 0.8010 - val_loss: 0.4564 - val_acc: 0.7665\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.4026 - acc: 0.7893 - val_loss: 0.4256 - val_acc: 0.7725\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3872 - acc: 0.8001 - val_loss: 0.4541 - val_acc: 0.7680\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3799 - acc: 0.8056 - val_loss: 0.4351 - val_acc: 0.7690\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3801 - acc: 0.8007 - val_loss: 0.4384 - val_acc: 0.7655\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s - loss: 0.3719 - acc: 0.8071 - val_loss: 0.4414 - val_acc: 0.7825\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3797 - acc: 0.8030 - val_loss: 0.4380 - val_acc: 0.7725\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3701 - acc: 0.8137 - val_loss: 0.4245 - val_acc: 0.7690\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3784 - acc: 0.8094 - val_loss: 0.4513 - val_acc: 0.7715\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3646 - acc: 0.8140 - val_loss: 0.4418 - val_acc: 0.7625\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3752 - acc: 0.8026 - val_loss: 0.4528 - val_acc: 0.7545\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3619 - acc: 0.8125 - val_loss: 0.4630 - val_acc: 0.7655\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3564 - acc: 0.8190 - val_loss: 0.4537 - val_acc: 0.7525\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3485 - acc: 0.8231 - val_loss: 0.4504 - val_acc: 0.7800\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3506 - acc: 0.8235 - val_loss: 0.4747 - val_acc: 0.7535\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3491 - acc: 0.8236 - val_loss: 0.4341 - val_acc: 0.7745\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3422 - acc: 0.8285 - val_loss: 0.4453 - val_acc: 0.7700\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3416 - acc: 0.8265 - val_loss: 0.4352 - val_acc: 0.7665\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3445 - acc: 0.8293 - val_loss: 0.4754 - val_acc: 0.7605\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3320 - acc: 0.8339 - val_loss: 0.4624 - val_acc: 0.7630\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3322 - acc: 0.8345 - val_loss: 0.4706 - val_acc: 0.7620\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3274 - acc: 0.8420 - val_loss: 0.4676 - val_acc: 0.7510\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3255 - acc: 0.8389 - val_loss: 0.4731 - val_acc: 0.7545\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3216 - acc: 0.8393 - val_loss: 0.4599 - val_acc: 0.7630\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3195 - acc: 0.8425 - val_loss: 0.4780 - val_acc: 0.7665\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3098 - acc: 0.8465 - val_loss: 0.4656 - val_acc: 0.7565\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3065 - acc: 0.8506 - val_loss: 0.4713 - val_acc: 0.7615\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3300 - acc: 0.8326 - val_loss: 0.4657 - val_acc: 0.7650\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3188 - acc: 0.8459 - val_loss: 0.4849 - val_acc: 0.7465\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.3002 - acc: 0.8554 - val_loss: 0.4724 - val_acc: 0.7670\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2999 - acc: 0.8548 - val_loss: 0.4902 - val_acc: 0.7630\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2895 - acc: 0.8630 - val_loss: 0.5119 - val_acc: 0.7595\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2898 - acc: 0.8624 - val_loss: 0.5251 - val_acc: 0.7355\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2879 - acc: 0.8635 - val_loss: 0.5004 - val_acc: 0.7575\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2887 - acc: 0.8609 - val_loss: 0.5048 - val_acc: 0.7590\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2746 - acc: 0.8689 - val_loss: 0.5305 - val_acc: 0.7615\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2704 - acc: 0.8714 - val_loss: 0.5182 - val_acc: 0.7470\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2673 - acc: 0.8736 - val_loss: 0.5297 - val_acc: 0.7615\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2710 - acc: 0.8680 - val_loss: 0.5529 - val_acc: 0.7510\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2664 - acc: 0.8729 - val_loss: 0.5251 - val_acc: 0.7575\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s - loss: 0.2519 - acc: 0.8834 - val_loss: 0.6020 - val_acc: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10a520518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import csv\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim = 2*EMBED_DIM, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'saved_models/'\n",
    "if not os.path.exists(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "model.save_weights(model_directory +'model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radnom Evaluation using keras trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 60,601\n",
      "Trainable params: 60,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model = model.load_weights(model_directory + 'model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 'Mary is in the building . John goes to the market . Mary leaves the building . Carol went to the office . Jim travelled to the building .'\n",
    "q = 'Is John in the market ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = [x.lower() for x in i.split()]\n",
    "que = [x.lower() for x in q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'is', 'in', 'the', 'building', '.', 'john', 'goes', 'to', 'the', 'market', '.', 'mary', 'leaves', 'the', 'building', '.', 'carol', 'went', 'to', 'the', 'office', '.', 'jim', 'travelled', 'to', 'the', 'building', '.']\n",
      "['is', 'john', 'in', 'the', 'market', '?']\n"
     ]
    }
   ],
   "source": [
    "print (inp)\n",
    "print (que)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding closest word to a given word for unknown words encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(word1, word2):\n",
    "    dot = np.dot(word1, word2)\n",
    "    norm_u = np.sqrt(np.sum(np.power(word1, 2)))\n",
    "    norm_v = np.sqrt(np.sum(np.power(word2, 2)))\n",
    "    cosine_similarity = dot/ (norm_u*norm_v)\n",
    "    \n",
    "    return cosine_similarity\n",
    "\n",
    "def find_closest(word):\n",
    "    dist = -100.0\n",
    "    for w, vec in embedding_file.items():\n",
    "        if word == w:\n",
    "            continue\n",
    "            \n",
    "        cosine_sim = cosine(embedding_file[word], vec)\n",
    "        if cosine_sim > dist:\n",
    "            dist = cosine_sim\n",
    "            closest = w\n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "susan\n"
     ]
    }
   ],
   "source": [
    "print (find_closest('Carol'.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_vec = np.array([embedding_file[w] if w in embedding_file else embedding_file[find_closest[w]] for w in inp])\n",
    "que_vec = np.array([embedding_file[w] if w in embedding_file else embedding_file[find_closest[w]] for w in que])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 50) (6, 50)\n"
     ]
    }
   ],
   "source": [
    "print (inp_vec.shape, que_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_v = np.zeros((1, 50))\n",
    "q_v = np.zeros((1, 50))\n",
    "\n",
    "for c in inp_vec:\n",
    "    i_v += c\n",
    "\n",
    "for c in que_vec:\n",
    "    q_v += c  \n",
    "    \n",
    "pred_x = np.concatenate((i_v, q_v), 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98502076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.squeeze(model.predict(pred_x))\n",
    "print (p)\n",
    "'Yes' if p > 0.5 else 'NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
